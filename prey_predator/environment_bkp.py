# -*- coding: utf-8 -*-
"""
Created on Nov 3 

@author: Felipe Leno
Environment for the predator-prey domain
"""
import random 
import math
from scipy.spatial import distance
import time
import actions

class PredatorPreyEnvironment(object):
    #Environment Size    
    sizeX = 10
    sizeY = 10
    
    
        
    
    #Default Environment Rewards
    capturedReward = +1
    defaultReward = 0  
    
    outGridValue = None
    
    
    
    agentVisualDepth = 3
    
    reward = None
    lastTerminal = False
    
    numberAgents = None
    numberPreys = None
    agents = None
    
    agentPositions = None
    preyPositions = None
    caught = None
    
    #Agent class objects
    agents = None
    

    storedInitialPositions = None
    lastEvalEps = 0
    agentActions = None
    
    
    #Controls the state transition (for agents running in parallel)
    completedTransition = None
    
    def __init__(self,numberAgents,agents,preys,evalEpisodes):
        """Prepares the environment class:
            numberAgents = the number of agents in the simulation
            agents = the agents objects (subclass of Agent)
            evalEpisodes = the number of evaluation episodes
            parallelAgents = if the agents are running in parallel
        """
        self.numberAgents = numberAgents
        self.numberPreys = preys
        self.agents = agents
           
        self.agentActions = [None]*numberAgents
        
        self.agentPositions = [None]*numberAgents
        self.storedInitialPositions = [None]*evalEpisodes
        self.preyPositions = [None]*preys
        self.caught = [None]*preys
        
        self.build_eval_eps(evalEpisodes)
        self.outGridValue = -99

        
    def act(self,agentID,action):
        """Performs an action.
        This function performs nothing until the last agent chooses its action.
        Then, the state transition is activated"""
        self.agentActions[agentID] = action
        
        
    def step(self,agentID):
        """Waits until all the agents applied their actions and the state transition is completed
           The return is statePrime.action,reward"""              
        statePrime = self.get_state(agentID)           
        reward = self.observe_reward(agentID)        
        action = self.agentActions[agentID]
        
        return statePrime,action,reward
    
    def finish_state_transition(self):
        """Executed when all agents completed their state transition procedures"""
        self.state_transition()        
        #self.agentActions = [None]*self.numberAgents

        
        
    def state_transition(self):
        """Executes the state transition"""
        preyIndex = 0        
        
        #Process the prey movement
        for preyP in self.preyPositions:
            #No need to move a captured prey            
            if self.caught[preyIndex]:
                if preyP[0] != self.outGridValue:
                    self.preyPositions[preyIndex][0] = self.outGridValue
                    self.preyPositions[preyIndex][1] = self.outGridValue
            else: #The prey was not captured yet        
                preyMove = random.randint(0,actions.preyActions-1)
                offsetX = 0
                offsetY = 0
                if  (preyMove == actions.NORTH):
                    offsetX = 0
                    offsetY = 1
                elif(preyMove == actions.SOUTH):
                    offsetX = 0
                    offsetY = -1           
                elif(preyMove == actions.EAST):
                    offsetX = 1
                    offsetY = 0 
                elif(preyMove == actions.WEST):
                    offsetX = -1
                    offsetY = 0
                    
                self.preyPositions[preyIndex][0] = self.preyPositions[preyIndex][0] + offsetX
                self.preyPositions[preyIndex][1] = self.preyPositions[preyIndex][1] + offsetY
                
                #movements towards walls
                if(self.preyPositions[preyIndex][0] <= 0):
                    self.preyPositions[preyIndex][0] = 1
                elif(self.preyPositions[preyIndex][0] > self.sizeX):
                    self.preyPositions[preyIndex][0] = self.sizeX
                    
                if(self.preyPositions[preyIndex][1] <= 0):
                    self.preyPositions[preyIndex][1] = 1
                elif(self.preyPositions[preyIndex][1] > self.sizeY):
                    self.preyPositions[preyIndex][1] = self.sizeY
            preyIndex += 1
        
        # Move all agents
        agentIndex = 0
        for agentP in self.agentPositions:
            agtMove = self.agentActions[agentIndex]
            
            if  (agtMove == actions.NORTH):
                offsetX = 0
                offsetY = 1
            elif(agtMove == actions.SOUTH):
                offsetX = 0
                offsetY = -1           
            elif(agtMove == actions.EAST):
                offsetX = 1
                offsetY = 0 
            elif(agtMove == actions.WEST):
                offsetX = -1
                offsetY = 0
            self.agentPositions[agentIndex][0] = self.agentPositions[agentIndex][0] + offsetX
            self.agentPositions[agentIndex][1] = self.agentPositions[agentIndex][1] + offsetY
            
            #movements towards walls
            if(self.agentPositions[agentIndex][0] <= 0):
                self.agentPositions[agentIndex][0] = 1
            elif(self.agentPositions[agentIndex][0] > self.sizeX):
                self.agentPositions[agentIndex][0] = self.sizeX
                
            if(self.agentPositions[agentIndex][1] <= 0):
                 self.agentPositions[agentIndex][1] = 1
            elif(self.agentPositions[agentIndex][1] > self.sizeY):
                 self.agentPositions[agentIndex][1] = self.sizeY
            agentIndex += 1
        #Updates the terminal state variable
        self.check_terminal()
        if self.reward == 0:
            self.reward = self.defaultReward


            
    def check_terminal(self):
        """Checks if the current state is terminal"""
        self.reward = 0        
        preyIndex = 0
        
        for preyP in self.preyPositions:
            if not self.caught[preyIndex]:            
                agentIndex = 0
                while not self.caught[preyIndex] and agentIndex < self.numberAgents:
                    if(preyP[0] == self.agentPositions[agentIndex][0] and
                    preyP[1] == self.agentPositions[agentIndex][1]):
                       self.reward += self.capturedReward
                       self.caught[preyIndex] = True
                    agentIndex += 1
                
            self.lastTerminal = self.caught[preyIndex]
            if not self.caught[preyIndex]:
                return False
            preyIndex += 1

                 
            
        
        
    def get_state(self,agentID,sortFriends=True):
        """Returns the state for a given agent"""
        
        if self.lastTerminal:
            return tuple('end')
        #   ret = [0,0]
        #   for i in range(self.numberAgents-1):
        #       ret.append(float('inf'))
        #       ret.append(float('inf'))
        #   return tuple(ret)
        
        selfP = self.agentPositions[agentID]
        selfx = selfP[0]
        selfy = selfP[1]
        
        sensations = []
        
        preys = self.preyPositions
        
        if sortFriends:
            sortedPreys = sorted(preys,key=lambda i: distance.euclidean(i,selfP))
        else:
            sortedPreys = preys
        notFoundPreys = 0
        #preyx = self.preyPositions[0]        
        #preyy = self.preyPositions[1]
        for i in range(self.numberPreys):
            preyx = sortedPreys[i][0]
            preyy = sortedPreys[i][1]
            
            #sensations related to the prey
            offsetX = preyx - selfx
            offsetY = preyy - selfy
            
            if(math.fabs(offsetX)<= self.agentVisualDepth and math.fabs(offsetY)<= self.agentVisualDepth):
                 sensations.append(offsetX)
                 sensations.append(offsetY)
            else:
                if sortFriends:
                    notFoundPreys +=1
                else:
                 sensations.append(float('inf'))
                 sensations.append(float('inf'))
        if sortFriends:
            for i in range(notFoundPreys):
                sensations.append(float('inf'))
                sensations.append(float('inf'))
                


        #End of prey sensations

        #sensations related to other agents
        otherAg = [x for i,x in enumerate(self.agentPositions) if i!=agentID]
        
        #sort agents by distance
        if sortFriends:
            sortedAg = sorted(otherAg,key=lambda i: distance.euclidean(i,selfP))
        else:
            sortedAg = otherAg
        
        notUsedAg = 0
        for i in range(self.numberAgents-1):
             offsetX = sortedAg[i][0] - selfx
             offsetY = sortedAg[i][1] - selfy
             if(math.fabs(offsetX)<= self.agentVisualDepth and math.fabs(offsetY)<= self.agentVisualDepth):
                 sensations.append(offsetX)
                 sensations.append(offsetY)
             else:
                 notUsedAg += 1
        
        #Agents outside the visual depth
        for i in range(notUsedAg):
            sensations.append(float('inf'))
            sensations.append(float('inf'))
            
        
        
        sensations = tuple(sensations)
        
        return sensations
             
        
        
             
        
    def observe_reward(self,agentID):
        """Returns the reward for the agent"""
        return self.reward
        
    def is_terminal_state(self):
        return self.lastTerminal
        
    def start_evaluation_episode(self):
        """Start next evaluation episode"""
        randomState = random.getstate()
        
        import copy
        epInfo = copy.deepcopy(self.storedInitialPositions[self.lastEvalEps])
        self.load_episode(epInfo)
        #Prepares pointer for the next episode
        self.lastEvalEps = (self.lastEvalEps + 1) % len(self.storedInitialPositions)
        #Preys in random position
        notChosen = range(len(self.preyPositions))

        preyPosic = []        
        while len(notChosen) != 0:
            index = random.choice(notChosen)
            preyPosic.append(self.preyPositions[index])
            notChosen.remove(index)
        
        self.preyPositions = preyPosic
        
        #Agents in random position
        notChosen = range(len(self.agentPositions))

        agPosic = []        
        while len(notChosen) != 0:
            index = random.choice(notChosen)
            agPosic.append(self.agentPositions[index])
            notChosen.remove(index)
        
        self.agentPositions = agPosic
        
        self.caught = [False]*self.numberPreys        
        
        random.setstate(randomState)
        
            
                
        
        
        
    def start_learning_episode(self):
        """Starts episode with random initial positions"""
        epInfo = self.generate_episode_information()
        #epInfo = random.choice(self.storedInitialPositions) # ---
        self.load_episode(epInfo)
        self.caught = [False]*self.numberPreys
          

        
    def load_episode(self,episodeInfo):
        """Starts an episode geerated by the generate_episode_information() method"""
        self.preyPositions = episodeInfo[0]
        self.agentPositions = episodeInfo[1]
        self.reward = None #No last step reward
        self.lastTerminal = False
        
    def build_eval_eps(self,numEps):
        """Prepares the evaluation episodes for posterior use"""
        #self.storedInitialPositions = [[[5,5],[[1,1],[10,10],[1,10]]]]        
        for i in range(numEps):        
            self.storedInitialPositions[i] = self.generate_episode_information()
            
            
    def generate_episode_information(self):
        """Generates a random Episode"""
        
        allPreysPos = []
        for i in range(self.numberPreys):
            xprey = random.randint(1,self.sizeX)
            yprey = random.randint(1,self.sizeY)
            #Prey random initial Position        
            preyP = [xprey,yprey]
            allPreysPos.append(preyP)
        
        
        allAgentsP = []
        #Agents random initial position
        for i in range(self.numberAgents):
            #No terminal state is generated
            repeat = True
            while repeat:
                repeat = False
                index = 0
                xagent = random.randint(1,self.sizeX)
                yagent = random.randint(1,self.sizeY)
                while not repeat and index<self.numberPreys:
                    if allPreysPos[index][0]==xagent and \
                        allPreysPos[index][1]==yagent:
                            repeat = True
                    index = index+1
            agentP = [xagent,yagent]
            allAgentsP.append(agentP)

        return [allPreysPos,allAgentsP]
            
        
            
            
        
    
    
        
        
        